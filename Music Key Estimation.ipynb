{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Music Key Estimation\n",
    "Notebook file to explore the processes required to estimate the music key.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "DATA_FOLDER = pathlib.Path(\"data\")\n",
    "AUDIO_DATA_FOLDER = pathlib.Path(\"data/audio\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook Setup\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 14, 8  # In inches\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Music Key Estimation\n",
    "We utilise the wonderful [KeyCNN](https://github.com/hendriks73/key-cnn) to make estimates about the key of a piece of music.\n",
    "\n",
    "Code below is adapted from KeyCNN.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define some utility functions that will come into use later.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ensure_length(data, length):\n",
    "    \"\"\"\n",
    "    Ensure that the data has a length of `length` along the 3rd dimension (1-indexed).\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the array to store the padded data\n",
    "    padded_data = np.zeros((1, data.shape[1], length, 1), dtype=data.dtype)\n",
    "\n",
    "    # Place the given data within the padded data\n",
    "    padded_data[0, :, 0:data.shape[2], 0] = data[0, :, :, 0]\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def add_zeros(data, num_zeros):\n",
    "    \"\"\"\n",
    "    Add `num_zeros` zeros to the data, with the data being centered.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the array to store the padded data\n",
    "    padded_data = np.zeros((1, data.shape[1], data.shape[2] + num_zeros, 1), dtype=data.dtype)\n",
    "\n",
    "    # Place the given data within the padded data\n",
    "    padded_data[0, :, num_zeros // 2:data.shape[2] + (num_zeros // 2), 0] = data[0, :, :, 0]\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def to_sliding_window(data, window_length, hop_length):\n",
    "    \"\"\"\n",
    "    Converts the given data array into separate sliding windows of length `window_length` separated by `hop_length`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of windows that we need\n",
    "    num_windows = ((data.shape[2] - window_length) // hop_length + 1) * hop_length\n",
    "\n",
    "    # Generate the windows\n",
    "    windowed_data = []\n",
    "    for offset in range(0, num_windows, hop_length):\n",
    "        windowed_data.append(np.copy(data[:, :, offset:window_length + offset, :]))\n",
    "\n",
    "    # Concatenate all the windows together and return\n",
    "    return np.concatenate(windowed_data, axis=0)\n",
    "\n",
    "def std_normalizer(data):\n",
    "    \"\"\"\n",
    "    Normalizes data to zero mean and unit variance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cast data as 64-bit float to avoid numpy warnings\n",
    "    data = data.astype(np.float64)\n",
    "\n",
    "    # Get existing mean and standard deviation of data\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "\n",
    "    # Normalize data\n",
    "    if std != 0.:\n",
    "        data = (data - mean) / std\n",
    "\n",
    "    # Now cast data back to 16-bit floats and return\n",
    "    return data.astype(np.float16)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create a function that will generate the `features` numpy array that will be used for key estimation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def read_features(file, num_frames=60, hop_length=30, zero_pad=False):\n",
    "    \"\"\"\n",
    "    Resample file to 22050 Hz, then transform using CQT with length 8192\n",
    "    and hop size 4096, ranging from E1 + 7 octaves with two semitones\n",
    "    per bin.\n",
    "\n",
    "    Since we require at least 60 frames, shorter audio excerpts are always\n",
    "    zero padded.\n",
    "\n",
    "    Specifically for keygram, 30 frames each can be added at the front and\n",
    "    at the back in order to make the calculation of key values for the first\n",
    "    and the last window possible.\n",
    "\n",
    "    Args:\n",
    "        file: File to load audio data from.\n",
    "        num_frames: Number of frames that we want.\n",
    "        hop_length: Hop length for the sliding window.\n",
    "        zero_pad: Whether to add 30 zero frames both at the front and back to the features array.\n",
    "\n",
    "    Returns:\n",
    "        A feature tensor for the whole file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constants\n",
    "    octaves = 7  # Number of octaves to generate\n",
    "    bins_per_semitone = 2  # Number of frequency bins per 'note'\n",
    "    bins_per_octave = 12 * bins_per_semitone  # Number of bins per octave (each octave has 12 semitones)\n",
    "    window_length = 8192\n",
    "\n",
    "    # Get the samples and sample rate of the audio file\n",
    "    y, sr = librosa.load(file, sr=22050)   # We set sample rate to 22050 for easier processing (and lesser data)\n",
    "\n",
    "    # Get the required data by running a CQT on the samples\n",
    "    data = np.abs(librosa.cqt(\n",
    "        y,\n",
    "        sr=sr,\n",
    "        hop_length=window_length // 2,\n",
    "        fmin=librosa.note_to_hz(\"E1\"),\n",
    "        n_bins=bins_per_octave * octaves,\n",
    "        bins_per_octave=bins_per_octave\n",
    "    ))\n",
    "\n",
    "    # Reshape the data\n",
    "    data = np.reshape(data, (1, data.shape[0], data.shape[1], 1))\n",
    "\n",
    "    # Add `num_frames/2` zero frames before and after the data\n",
    "    if zero_pad:\n",
    "        data = add_zeros(data, num_frames)\n",
    "\n",
    "    # If we have less than the required number of frames, zero-pad the data to make sure we get some result at all\n",
    "    if data.shape[2] < num_frames:\n",
    "        data = ensure_length(data, num_frames)\n",
    "\n",
    "    # Convert data to overlapping windows, where each window is one sample\n",
    "    return to_sliding_window(data, num_frames, hop_length)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we create functions that handle the estimation and interpretation of the estimation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def estimate_key_distribution(data, model):\n",
    "    \"\"\"\n",
    "    Estimate a key distribution.\n",
    "    Probabilities are indexed, starting with 30 BPM and ending with 286 BPM. (wait why bpm???)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the data is of the correct shape\n",
    "    assert len(data.shape) == 4, \"Input data must be four dimensional. Actual shape was \" + str(data.shape)\n",
    "    assert data.shape[1] == 168, \"Second dim of data must be 168. Actual shape was \" + str(data.shape)\n",
    "    assert data.shape[2] == 60, \"Third dim of data must be 60. Actual shape was \" + str(data.shape)\n",
    "    assert data.shape[3] == 1, \"Fourth dim of data must be 1. Actual shape was \" + str(data.shape)\n",
    "\n",
    "    # Normalize the data\n",
    "    norm_data = std_normalizer(data)\n",
    "\n",
    "    # Use the model to estimate the key distribution\n",
    "    return model.predict(norm_data, norm_data.shape[0])\n",
    "\n",
    "\n",
    "def estimate_key(data, model):\n",
    "    \"\"\"\n",
    "    Estimates the pre-dominant global key.\n",
    "    \"\"\"\n",
    "\n",
    "    # First estimate the key distribution\n",
    "    est_key_dist = estimate_key_distribution(data, model)\n",
    "\n",
    "    # Compute the averaged prediction distribution\n",
    "    avg_est_key_dist = np.average(est_key_dist, axis=0)\n",
    "\n",
    "    # Find the key with the highest probability\n",
    "    highest_key_index = np.argmax(avg_est_key_dist)\n",
    "\n",
    "    # Determine if the key is in minor or major mode\n",
    "    is_minor = highest_key_index >= 12\n",
    "\n",
    "    # Determine midi value of the key\n",
    "    key_midi_val = highest_key_index + 12 if not is_minor else highest_key_index\n",
    "\n",
    "    # Get the tonic and mode\n",
    "    tonic = librosa.midi_to_note(midi=key_midi_val, octave=False)\n",
    "    mode = \"Minor\" if is_minor else \"Major\"\n",
    "\n",
    "    # Concat and return\n",
    "    return f\"{tonic} {mode}\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Experiments\n",
    "\n",
    "Let's test the model on an example audio file, `Melancholy.wav`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need to load the model using Tensorflow.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 14:32:07.701481: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-13 14:32:07.701706: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "myModel = tf.keras.models.load_model(\"Model.h5\")  # See \"Update KeyCNN Models.ipynb\" to generate this model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's get a summary of the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DEEPSPEC_K8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_106 (InputLayer)      [(None, 168, None, 1)]    0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 168, None, 8)      48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 168, None, 8)      32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 168, None, 8)      200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 168, None, 8)      32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 84, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_630 (Dropout)       (None, 84, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 84, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 84, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 84, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 84, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 42, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_631 (Dropout)       (None, 42, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 42, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 42, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 42, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 42, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 21, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_632 (Dropout)       (None, 21, None, 32)      0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 21, None, 32)      5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 21, None, 32)      128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 21, None, 32)      3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 21, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_633 (Dropout)       (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_634 (Dropout)       (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_635 (Dropout)       (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 2, None, 24)       1560      \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 24)               0         \n",
      " 5 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " activation_105 (Activation)  (None, 24)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,480\n",
      "Trainable params: 73,616\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we load the features from the audio file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "audioFeatures = read_features(\"Melancholy.wav\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the shape of the features array?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 168, 60, 1)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioFeatures.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's estimate the tonic and mode of the audio file.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 14:32:09.730902: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-13 14:32:09.833769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "'C Major'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_key(audioFeatures, myModel)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}